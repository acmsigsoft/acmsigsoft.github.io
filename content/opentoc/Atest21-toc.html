<html xmlns:bkstg="http://www.atypon.com/backstage-ns" xmlns:urlutil="java:com.atypon.literatum.customization.UrlUtil" xmlns:pxje="java:com.atypon.frontend.services.impl.PassportXslJavaExtentions">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <meta http-equiv="Content-Style-Type" content="text/css">
      <style type="text/css">
            #DLtoc {
            font: normal 12px/1.5em Arial, Helvetica, sans-serif;
            }

            #DLheader {
            }
            #DLheader h1 {
            font-size:16px;
            }

            #DLcontent {
            font-size:12px;
            }
            #DLcontent h2 {
            font-size:14px;
            margin-bottom:5px;
            }
            #DLcontent h3 {
            font-size:12px;
            padding-left:20px;
            margin-bottom:0px;
            }

            #DLcontent ul{
            margin-top:0px;
            margin-bottom:0px;
            }

            .DLauthors li{
            display: inline;
            list-style-type: none;
            padding-right: 5px;
            }

            .DLauthors li:after{
            content:",";
            }
            .DLauthors li.nameList.Last:after{
            content:"";
            }

            .DLabstract {
            padding-left:40px;
            padding-right:20px;
            display:block;
            }

            .DLformats li{
            display: inline;
            list-style-type: none;
            padding-right: 5px;
            }

            .DLformats li:after{
            content:",";
            }
            .DLformats li.formatList.Last:after{
            content:"";
            }

            .DLlogo {
            vertical-align:middle;
            padding-right:5px;
            border:none;
            }

            .DLcitLink {
            margin-left:20px;
            }

            .DLtitleLink {
            margin-left:20px;
            }

            .DLotherLink {
            margin-left:0px;
            }

        </style>
      <title>A-TEST 2021: Proceedings of the 12th International Workshop on Automating TEST Case Design, Selection, and Evaluation</title>
   </head>
   <body>
      <div id="DLtoc">
         <div id="DLheader">
            <h1>A-TEST 2021: Proceedings of the 12th International Workshop on Automating TEST Case Design, Selection,
               and Evaluation</h1><a class="DLcitLink" title="Go to the ACM Digital Library for additional information about this proceeding" referrerpolicy="no-referrer-when-downgrade" href="https://dl.acm.org/doi/proceedings/10.1145/3472672"><img class="DLlogo" alt="Digital Library logo" height="30" src="https://dl.acm.org/specs/products/acm/releasedAssets/images/footer-logo1.png">
               Full Citation in the ACM Digital Library
               </a></div>
         <div id="DLcontent">
            <h2>SESSION: Automated Testing</h2>
            						
            <h3><a class="DLtitleLink" title="Full Citation in the ACM Digital Library" referrerpolicy="no-referrer-when-downgrade" href="https://dl.acm.org/doi/10.1145/3472672.3473952">Using an agent-based approach for robust automated testing of computer games</a></h3>
            <ul class="DLauthors">
               <li class="nameList">Samira Shirzadehhajimahmood</li>
               <li class="nameList">I. S. W. B. Prasetya</li>
               <li class="nameList">Frank Dignum</li>
               <li class="nameList">Mehdi Dastani</li>
               <li class="nameList Last">Gabriele Keller</li>
            </ul>
            <div class="DLabstract">
               <div style="display:inline">
                  		
                  <p>Modern computer games typically have a huge interaction spaces and non-deterministic
                     environments. Automation in testing can provide a vital boost in development and it
                     further improves the overall software's reliability and efficiency. Moreover, layout
                     and game logic may regularly change during development or consecutive releases which
                     makes it difficult to test because the usage of the system continuously changes. To
                     deal with the latter, tests also need to be robust. Unfortunately, existing game testing
                     approaches are not capable of maintaining test robustness. To address these challenges,
                     this paper presents an agent-based approach for robust automated testing based on
                     the reasoning type of AI.</p>
                  	</div>
            </div>
            						
            					
            						
            <h3><a class="DLtitleLink" title="Full Citation in the ACM Digital Library" referrerpolicy="no-referrer-when-downgrade" href="https://dl.acm.org/doi/10.1145/3472672.3473953">Towards automated generation of PO-based WebDriver test suites from Selenium IDE recordings</a></h3>
            <ul class="DLauthors">
               <li class="nameList">Filippo Ricca</li>
               <li class="nameList Last">Maurizio Leotta</li>
            </ul>
            <div class="DLabstract">
               <div style="display:inline">
                  		
                  <p>Modern web applications require long quality assurance sessions to be appreciated
                     by users. Test automation reduces delivery times but requires the development of effective
                     and maintainable test scripts so that the advantages of its use are not lost. </p> 
                  <p> The usage of the Page object (PO) pattern has proven to be very effective in GUI
                     testing, however, the manual development of Page objects, a sort of web page facade
                     exposing methods to the test scripts, requires a relevant effort, which is often only
                     repaid during evolution. </p> 
                  <p> In this paper, we describe a novel approach, almost totally automated, that takes
                     advantage of the features offered by Selenium IDE for generating more maintainable
                     Selenium WebDriver test scripts and Page objects for web applications. The only manual
                     step required to the tester/developer is to add comments to the Selenese produced
                     by Selenium IDE during registrations through a plugin. The very first estimate we
                     conducted to evaluate our tool-based approach appears to be promising.</p>
                  	</div>
            </div>
            						
            					
            						
            <h3><a class="DLtitleLink" title="Full Citation in the ACM Digital Library" referrerpolicy="no-referrer-when-downgrade" href="https://dl.acm.org/doi/10.1145/3472672.3473954">Automated translation of Android context-dependent gestures to visual GUI test instructions</a></h3>
            <ul class="DLauthors">
               <li class="nameList">Riccardo Coppola</li>
               <li class="nameList">Luca Ardito</li>
               <li class="nameList Last">Marco Torchiano</li>
            </ul>
            <div class="DLabstract">
               <div style="display:inline">
                  		
                  <p>Layout-based (2nd Generation) and Visual (3rd Generation) GUI testing are two very
                     common approaches for mobile application testing. The two techniques expose complementary
                     advantages and drawbacks, and the literature on GUI Testing has highlighted the benefits
                     of an approach based on a translation from one generation to the other. </p> 
                  <p> The objective of this work is to provide an improvement to our prototype tool, TOGGLE,
                     designed to translate 2nd Generation test suites, written with the Espresso framework,
                     to 3rd Generation ones that can be run by the EyeAutomate and Sikuli tool. </p> 
                  <p> We extended TOGGLE by adding (1) support for context-based gestures, performed through
                     the scrollTo and onData commands, and (2) support for the combination of Layout-based
                     locators with logical operators. </p> 
                  <p> We evaluated the new version of the tool on five different experimental subjects.
                     For each of the applications, 30 test cases were developed and automatically translated
                     with TOGGLE+. </p> 
                  <p> We observed an increase of 68% of translatable test cases when transitioning from
                     the previous prototype to the current version of the tool. The generated Visual test
                     cases also proved to have high robustness, with flakiness of just 2% (i.e., 98% correct
                     executions).</p>
                  	</div>
            </div>
            						
            					
            <h2>SESSION: Industry and Embedded Systems</h2>
            						
            <h3><a class="DLtitleLink" title="Full Citation in the ACM Digital Library" referrerpolicy="no-referrer-when-downgrade" href="https://dl.acm.org/doi/10.1145/3472672.3473955">Integrating usage monitoring for continuous evaluation and testing in the UI of an
                  industry application</a></h3>
            <ul class="DLauthors">
               <li class="nameList">Stefan Fischer</li>
               <li class="nameList">Claus Klammer</li>
               <li class="nameList Last">Rudolf Ramler</li>
            </ul>
            <div class="DLabstract">
               <div style="display:inline">
                  		
                  <p>Developing interactive systems and testing with realistic scenarios requires a detailed
                     understanding of how these systems are used in their real environment. In this paper,
                     we report on our experience from implementing a usage monitoring approach for the
                     touch-enabled human machine interface of an industrial machine. The approach supports
                     automated recording of user interface events as basis for analyzing interactions of
                     users with the system. It collects information about navigation paths to different
                     screens, activities on these screens, and the usage of functionality provided by the
                     application. We evaluated three different approaches to integrate the required usage
                     monitoring into the UI, considering aspects such as necessary changes to the existing
                     code base, dependencies to third-party libraries, and the entailed performance overhead.
                     The paper provides a detailed description of the implementation of the selected approach
                     and a discussion of the lessons we learned from integrating the monitoring in an existing
                     application.</p>
                  	</div>
            </div>
            						
            					
            						
            <h3><a class="DLtitleLink" title="Full Citation in the ACM Digital Library" referrerpolicy="no-referrer-when-downgrade" href="https://dl.acm.org/doi/10.1145/3472672.3473956">Towards a workflow for model-based testing of embedded systems</a></h3>
            <ul class="DLauthors">
               <li class="nameList">Muhammad Nouman Zafar</li>
               <li class="nameList">Wasif Afzal</li>
               <li class="nameList Last">Eduard Enoiu</li>
            </ul>
            <div class="DLabstract">
               <div style="display:inline">
                  		
                  <p>Model-based testing (MBT) has been previously used to validate embedded systems. However,
                     (i) creation of a model conforming to the behavioural aspects of an embedded system,
                     (ii) generation of executable test scripts and (iii) assessment of test verdict, re-quires
                     a systematic process. In this paper, we have presented a three-phase tool-supported
                     MBT workflow for the testing of an embedded system, that spans from requirements specification
                     to test verdict assessment. The workflow starts with a simplistic, yet practical,
                     application of a Domain-Specific Language (DSL) based on Gherkin-like style, which
                     allows the requirements engineer to specify requirements and to extract information
                     about model elements(i.e. states and transitions). This is done to assist the graphical
                     modelling of the complete system under test (SUT). Later stages of the workflow generates
                     an executable test script that runs on a domain-specific simulation platform. We have
                     evaluated this tool-supported workflow by specifying the requirements, extracting
                     information from the DSL and developing a model of a subsystem of the train control
                     management system developed at Alstom Transport AB in Sweden. The C# test script generated
                     from the SUT model is successfully executed at the Software-in-the-Loop (SIL) execution
                     platform and test verdicts are visualized as a sequence of passed and failed test
                     steps.</p>
                  	</div>
            </div>
            						
            					</div>
      </div>
   </body>
</html>