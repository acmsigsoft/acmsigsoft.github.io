
<!doctype html>
<head>
<META http-equiv="Content-Style-Type" content="text/css">
<title>FairWare '18- Proceedings of the International Workshop on Software Fairness</title>
<STYLE type="text/css">
#DLtoc {
	font: normal 12px/1.5em Arial, Helvetica, sans-serif;
	}

#DLheader {
	}
#DLheader h1 {
	font-size:16px;	
}
	
#DLcontent {
	 font-size:12px;
	}
#DLcontent h2 {
	 font-size:14px;
	 margin-bottom:5px;
	}
#DLcontent h3 {
	 font-size:12px;
	 padding-left:20px;
	 margin-bottom:0px;
	}

#DLcontent ul{
	margin-top:0px;
	margin-bottom:0px;
	}
		
.DLauthors li{
	display: inline;
	list-style-type: none;
	padding-right: 5px;
	}
	
.DLauthors li:after{
	content:",";
	}
.DLauthors li.nameList.Last:after{
	content:"";
	}		

.DLabstract {
	 padding-left:40px;
	 padding-right:20px;
	 display:block;
	}

.DLformats li{
	display: inline;
	list-style-type: none;
	padding-right: 5px;
	}
	
.DLformats li:after{
	content:",";
	}
.DLformats li.formatList.Last:after{
	content:"";
	}		

.DLlogo {
	vertical-align:middle; 
	padding-right:5px;
	border:none;
	}
	
.DLcitLink {
	margin-left:20px;
	}	

.DLtitleLink {
	margin-left:20px;
	}	

.DLotherLink {
	margin-left:0px;
	}		
   
</STYLE>
</head>
<body>
<div id="DLtoc">
<div id="DLheader">
<h1>FairWare '18- Proceedings of the International Workshop on Software Fairness</h1>
<a class="DLcitLink" href="https://urldefense.proofpoint.com/v2/url?u=https-3A__dl.acm.org_citation.cfm-3Fid-3D3194770&d=DwMFAg&c=clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=ZHuLpaRqk3Uz8lrvKUHs4g&m=UrGAxxNi3yz3xACFnPLBwTMSAkNuXqBPAXfDeLN1Gkw&s=24pMlqHw3d5XkFC9q5UpnqWHTXCvDZ-CUnmOCR5zmLc&e=" title="Go to the ACM Digital Library for additional information about this proceeding"><img class="DLlogo" src="https://dl.acm.org/img/dllogo.png" alt="Digital Library logo" height="30" width="30">Full Citation in the ACM Digital Library</a>
</div>
<div id="DLcontent">
<h2>SESSION: Fairness definitions and guarantees</h2>
<div class="DLabstract"> </div>
<h3>
<a class="DLtitleLink" href="https://urldefense.proofpoint.com/v2/url?u=https-3A__dl.acm.org_authorize-3FN652047&d=DwMFAg&c=clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=ZHuLpaRqk3Uz8lrvKUHs4g&m=UrGAxxNi3yz3xACFnPLBwTMSAkNuXqBPAXfDeLN1Gkw&s=s-jZZpyo9NHGEUiJ6wJtAHBxHwpFjAGBtyqtBdDJ5rw&e=" title="Get the Full Text from the ACM Digital Library">Fairness definitions explained</a>
</h3>
<ul class="DLauthors">
<li class="nameList First">Sahil Verma</li>
<li class="nameList Last">Julia Rubin</li>
</ul>
<div class="DLabstract"><div style="display:inline"><p>Algorithm fairness has started to attract the attention of researchers in AI, Software Engineering and Law communities, with more than twenty different notions of fairness proposed in the last few years. Yet, there is no clear agreement on which definition to apply in each situation. Moreover, the detailed differences between multiple definitions are difficult to grasp. To address this issue, this paper collects the most prominent definitions of fairness for the algorithmic classification problem, explains the rationale behind these definitions, and demonstrates each of them on a single unifying case-study. Our analysis intuitively explains why the same case can be considered fair according to some definitions and unfair according to others.</p></div> </div>
<h2>SESSION: Society and ethics</h2>
<div class="DLabstract"> </div>
<h3>
<a class="DLtitleLink" href="https://urldefense.proofpoint.com/v2/url?u=https-3A__dl.acm.org_authorize-3FN652048&d=DwMFAg&c=clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=ZHuLpaRqk3Uz8lrvKUHs4g&m=UrGAxxNi3yz3xACFnPLBwTMSAkNuXqBPAXfDeLN1Gkw&s=gKUhVusv6wS_UYSQrMVYS_MroCTWW6jdSBeElXF8ay8&e=" title="Get the Full Text from the ACM Digital Library">Integrating social values into software design patterns</a>
</h3>
<ul class="DLauthors">
<li class="nameList First">Waqar Hussain</li>
<li class="nameList">Davoud Mougouei</li>
<li class="nameList Last">Jon Whittle</li>
</ul>
<div class="DLabstract"><div style="display:inline"><p>Software Design Patterns (SDPs) are core solutions to the recurring problems in software. However, adopting SDPs without taking into account their value implications may result in breach of social values and ultimately lead to user dissatisfaction, lack of adoption, and financial loss. An example is the airline system that overcharged people who were trying to escape from the Hurricane Irma. Although not intentional, overlsight of social values in the design of the airline system resulted in significant customer dissatisfaction and loss of trust. To mitigate such value breaches in software design we propose taking social values into account in SDPs explicitly. To achieve this, we outline a collaborative framework that allows for (i) specifying the value implications of SDPs, (ii) developing or extending SDPs for integrating social values, (iii) providing guidance on the value-conscious adoption of design patterns, (iv) collecting and analyzing insights from collaborators, (v) maintaining an up-to-date library of the valufied design patterns, and (vi) incorporating lessons learned from the real-world adoption of the valuefied design patterns into the proposed framework for its continuous improvement in integrating social values into software.</p></div> </div>
<h3>
<a class="DLtitleLink" href="https://urldefense.proofpoint.com/v2/url?u=https-3A__dl.acm.org_authorize-3FN652049&d=DwMFAg&c=clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=ZHuLpaRqk3Uz8lrvKUHs4g&m=UrGAxxNi3yz3xACFnPLBwTMSAkNuXqBPAXfDeLN1Gkw&s=FGHD_yy93IqExuvm-l6XllUURLKSDCYw1UuyilSYeqM&e=" title="Get the Full Text from the ACM Digital Library">A roadmap for ethics-aware software engineering</a>
</h3>
<ul class="DLauthors">
<li class="nameList First">Fatma Ba&#351;ak Aydemir</li>
<li class="nameList Last">Fabiano Dalpiaz</li>
</ul>
<div class="DLabstract"><div style="display:inline"><p>Today's software is highly intertwined with our lives, and it possesses an increasing ability to act and influence us. Besides the renown example of self-driving cars and their potential harmfulness, more mundane software such as social networks can introduce bias, break privacy preferences, lead to digital addiction, etc. Additionally, the software engineering (SE) process itself is highly affected by ethical issues, such as diversity and business ethics. This paper introduces ethics-aware SE, a version of SE in which the ethical values of the stakeholders (including developers and users) are captured, analyzed, and reflected in software specifications and in the SE processes. We propose an analytical framework that assists stakeholders in analyzing ethical issues in terms of subject (software artifact or SE process), relevant value (diversity, privacy, autonomy, ...), and threatened object (user, developer, ...). We also define a roadmap that illustrates the necessary steps for the SE research and practice community in order to fully realize ethics-aware SE.</p></div> </div>
<h2>SESSION: Methods and applications</h2>
<div class="DLabstract"> </div>
<h3>
<a class="DLtitleLink" href="https://urldefense.proofpoint.com/v2/url?u=https-3A__dl.acm.org_authorize-3FN652040&d=DwMFAg&c=clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=ZHuLpaRqk3Uz8lrvKUHs4g&m=UrGAxxNi3yz3xACFnPLBwTMSAkNuXqBPAXfDeLN1Gkw&s=4Eq04jXHSqrU1CPrP4noNiaEyyaEez5hVhnthig0b7U&e=" title="Get the Full Text from the ACM Digital Library">Model-based discrimination analysis: a position paper</a>
</h3>
<ul class="DLauthors">
<li class="nameList First">Qusai Ramadan</li>
<li class="nameList">Amir Shayan Ahmadian</li>
<li class="nameList">Daniel Str&#252;ber</li>
<li class="nameList">Jan J&#252;rjens</li>
<li class="nameList Last">Steffen Staab</li>
</ul>
<div class="DLabstract"><div style="display:inline"><p>Decision-making software may exhibit biases due to hidden dependencies between protected characteristics and the data used as input for making decisions. To uncover such dependencies, we propose the development of a framework to support discrimination analysis during the system design phase, based on system models and available data.</p></div> </div>
<h3>
<a class="DLtitleLink" href="https://urldefense.proofpoint.com/v2/url?u=https-3A__dl.acm.org_authorize-3FN652041&d=DwMFAg&c=clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=ZHuLpaRqk3Uz8lrvKUHs4g&m=UrGAxxNi3yz3xACFnPLBwTMSAkNuXqBPAXfDeLN1Gkw&s=lu1RhkwclvUaownBK5BvJ_WXCQMfkDpnSlEuj1BZro4&e=" title="Get the Full Text from the ACM Digital Library">On fairness in continuous electronic markets</a>
</h3>
<ul class="DLauthors">
<li class="nameList Last">Hayden Melton</li>
</ul>
<div class="DLabstract"><div style="display:inline"><p>Most of the world's financial markets are <i>electronic</i> (i.e., are implemented as software systems) and <i>continuous</i> (i.e., process orders received from market participants immediately, on a FIFO basis). In this short position paper I argue that such markets cannot provide 'racetrack fairness' to their participants, yet this form of fairness seems to feature quite prominently throughout the large, multi-jurisdictional body of law governing financial markets. What seems to follow from this is that electronic <i>batch-style</i> markets are not only a <i>desirable</i> replacement for continuous ones---as a number of economists have recently argued---but a <i>necessary</i> replacement.</p></div> </div>
<h3>
<a class="DLtitleLink" href="https://urldefense.proofpoint.com/v2/url?u=https-3A__dl.acm.org_authorize-3FN652042&d=DwMFAg&c=clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=ZHuLpaRqk3Uz8lrvKUHs4g&m=UrGAxxNi3yz3xACFnPLBwTMSAkNuXqBPAXfDeLN1Gkw&s=2m51RAk3undCwWHrMZ3MPu0eJ3R81YpmDqrRNgqj_-U&e=" title="Get the Full Text from the ACM Digital Library">Avoiding the intrinsic unfairness of the trolley problem</a>
</h3>
<ul class="DLauthors">
<li class="nameList First">Tobias Holstein</li>
<li class="nameList Last">Gordana Dodig-Crnkovic</li>
</ul>
<div class="DLabstract"><div style="display:inline"><p>As an envisaged future of transportation, self-driving cars are being discussed from various perspectives, including social, economical, engineering, computer science, design, and ethical aspects. On the one hand, self-driving cars present new engineering problems that are being gradually successfully solved. On the other hand, social and ethical problems have up to now being presented in the form of an idealized unsolvable decision-making problem, the so-called "trolley problem", which is built on the assumptions that are neither technically nor ethically justifiable. The intrinsic unfairness of the trolley problem comes from the assumption that lives of different people have different values.</p> <p>In this paper, techno-social arguments are used to show the infeasibility of the trolley problem when addressing the ethics of self-driving cars. We argue that different components can contribute to an "unfair" behaviour and features, which requires ethical analysis on multiple levels and stages of the development process. Instead of an idealized and intrinsically unfair thought experiment, we present real-life techno-social challenges relevant for the domain of software fairness in the context of self-driving cars.</p></div> </div>
<h2>SESSION: Fairness standards</h2>
<div class="DLabstract"> </div>
<h3>
<a class="DLtitleLink" href="https://urldefense.proofpoint.com/v2/url?u=https-3A__dl.acm.org_authorize-3FN652043&d=DwMFAg&c=clK7kQUTWtAVEOVIgvi0NU5BOUHhpN0H8p7CSfnc_gI&r=ZHuLpaRqk3Uz8lrvKUHs4g&m=UrGAxxNi3yz3xACFnPLBwTMSAkNuXqBPAXfDeLN1Gkw&s=W3pngsbnGtixa-o8u4iX6ZQtx7WsLJ6sKHJEjII6ZvU&e=" title="Get the Full Text from the ACM Digital Library">IEEE P7003&trade; standard for algorithmic bias considerations: work in progress paper</a>
</h3>
<ul class="DLauthors">
<li class="nameList First">Ansgar Koene</li>
<li class="nameList">Liz Dowthwaite</li>

<li class="nameList Last">Suchana Seth</li>
</ul>
<div class="DLabstract"><div style="display:inline"><p>The IEEE P7003 Standard for Algorithmic Bias Considerations is one of eleven IEEE ethics related standards currently under development as part of the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. The purpose of the IEEE P7003 standard is to provide individuals or organizations creating algorithmic systems with development framework to avoid unintended, unjustified and inappropriately differential outcomes for users. In this paper, we present the scope and structure of the IEEE P7003 draft standard, and the methodology of the development process.</p></div> </div>
</div>
</div>
</body>
</html>
