
<!doctype html>
<head>
<META http-equiv="Content-Style-Type" content="text/css">
<title>SEFAIS '18- Proceedings of the 1st International Workshop on Software Engineering for AI in Autonomous Systems</title>
<STYLE type="text/css">
#DLtoc {
	font: normal 12px/1.5em Arial, Helvetica, sans-serif;
	}

#DLheader {
	}
#DLheader h1 {
	font-size:16px;	
}
	
#DLcontent {
	 font-size:12px;
	}
#DLcontent h2 {
	 font-size:14px;
	 margin-bottom:5px;
	}
#DLcontent h3 {
	 font-size:12px;
	 padding-left:20px;
	 margin-bottom:0px;
	}

#DLcontent ul{
	margin-top:0px;
	margin-bottom:0px;
	}
		
.DLauthors li{
	display: inline;
	list-style-type: none;
	padding-right: 5px;
	}
	
.DLauthors li:after{
	content:",";
	}
.DLauthors li.nameList.Last:after{
	content:"";
	}		

.DLabstract {
	 padding-left:40px;
	 padding-right:20px;
	 display:block;
	}

.DLformats li{
	display: inline;
	list-style-type: none;
	padding-right: 5px;
	}
	
.DLformats li:after{
	content:",";
	}
.DLformats li.formatList.Last:after{
	content:"";
	}		

.DLlogo {
	vertical-align:middle; 
	padding-right:5px;
	border:none;
	}
	
.DLcitLink {
	margin-left:20px;
	}	

.DLtitleLink {
	margin-left:20px;
	}	

.DLotherLink {
	margin-left:0px;
	}		
   
</STYLE>
</head>
<body>
<div id="DLtoc">
<div id="DLheader">
<h1>SEFAIS '18- Proceedings of the 1st International Workshop on Software Engineering for AI in Autonomous Systems</h1>
<a class="DLcitLink" href="https://dl.acm.org/citation.cfm?id=3194085" title="Go to the ACM Digital Library for additional information about this proceeding"><img class="DLlogo" src="https://dl.acm.org/img/dllogo.png" alt="Digital Library logo" height="30" width="30">Full Citation in the ACM Digital Library</a>
</div>
<div id="DLcontent">
<h2>SESSION: AI applications</h2>
<div class="DLabstract"> </div>
<h3>
<a class="DLtitleLink" href="https://dl.acm.org/authorize?N654006" title="Get the Full Text from the ACM Digital Library">A data-driven generative model for GPS sensors for autonomous driving</a>
</h3>
<ul class="DLauthors">
<li class="nameList First">Erik Karlsson</li>
<li class="nameList Last">Nasser Mohammadiha</li>
</ul>
<div class="DLabstract"><div style="display:inline"><p>Autonomous driving (AD) is envisioned to have a significant impact on people's life regarding safety and comfort. Positioning is one of the key challenges in realizing AD, where global navigation systems (GNSS) is traditionally used as an important source of information. The area of GNSS are well explored and the different sources of error are deeply investigated. However the existing modeling methods often have very comprehensive requirements for the training data where all affecting conditions such as ephemeris data should be well known. The main goal of this paper is to develop a solution to model GPS error that only requires information which is available in the vehicle without having access to detailed information about the conditions. We propose a statistical generative model using autoregression and Gaussian mixture models and develop a learning algorithm to estimate the parameters using the data collected in real traffic. The proposed model is evaluated by comparing the produced artificial data with the validation data collected at different traffic conditions and the results indicate that the model is successfully mimicking the sensor behavior.</p></div> </div>
<h3>
<a class="DLtitleLink" href="https://dl.acm.org/authorize?N654007" title="Get the Full Text from the ACM Digital Library">How machine perception relates to human perception: visual saliency and distance in a frame-by-frame semantic segmentation task for highly/fully automated driving</a>
</h3>
<ul class="DLauthors">
<li class="nameList First">Nico Herbig</li>
<li class="nameList">Frederik Wiehr</li>
<li class="nameList">Atanas Poibrenski</li>
<li class="nameList">Janis Sprenger</li>
<li class="nameList Last">Christian M&#252;ller</li>
</ul>
<div class="DLabstract"><div style="display:inline"><p>In this paper, we investigate the link between machine perception and human perception for highly/fully automated driving. We compare the classification results of a camera-based frame-by-frame semantic segmentation model (M<scp>achine</scp>) with a well-established visual saliency model (H<scp>uman</scp>) on the Cityscapes dataset. The results show that M<scp>achine</scp> classifies foreground objects better if they are more salient, indicating a similarity with the human visual system. For background objects, the accuracy drops when the saliency increases, giving evidence for the assumption that M<scp>achine</scp> has an implicit concept of saliency.</p></div> </div>
<h3>
<a class="DLtitleLink" href="https://dl.acm.org/authorize?N654008" title="Get the Full Text from the ACM Digital Library">Emotion-awareness for intelligent vehicle assistants: a research agenda</a>
</h3>
<ul class="DLauthors">
<li class="nameList First">Hans-J&#246;rg V&#246;gel</li>
<li class="nameList">Christian S&#252;&#223;</li>
<li class="nameList">Thomas Hubregtsen</li>
<li class="nameList">Viviane Ghaderi</li>
<li class="nameList">Ronee Chadowitz</li>
<li class="nameList">Elisabeth Andr&#233;</li>
<li class="nameList">Nicholas Cummins</li>
<li class="nameList">Bj&#246;rn Schuller</li>
<li class="nameList">J&#233;r&#244;me H&#228;rri</li>
<li class="nameList">Rapha&#235;l Troncy</li>
<li class="nameList">Benoit Huet</li>
<li class="nameList">Melek &#214;nen</li>
<li class="nameList">Adlen Ksentini</li>
<li class="nameList">J&#246;rg Conradt</li>
<li class="nameList">Asaf Adi</li>
<li class="nameList">Alexander Zadorojniy</li>
<li class="nameList">Jacques Terken</li>
<li class="nameList">Jonas Beskow</li>
<li class="nameList">Ann Morrison</li>
<li class="nameList">Kynan Eng</li>
<li class="nameList">Florian Eyben</li>
<li class="nameList">Samer Al Moubayed</li>
<li class="nameList Last">Susanne M&#252;ller</li>
</ul>
<div class="DLabstract"><div style="display:inline"><p>EVA<sup>1</sup> is describing a new class of emotion-aware autonomous systems delivering intelligent personal assistant functionalities. EVA requires a multi-disciplinary approach, combining a number of critical building blocks into a cybernetics systems/software architecture: emotion aware systems and algorithms, multimodal interaction design, cognitive modelling, decision making and recommender systems, emotion sensing as feedback for learning, and distributed (edge) computing delivering cognitive services.</p></div> </div>
<h2>SESSION: AI engineering methods</h2>
<div class="DLabstract"> </div>
<h3>
<a class="DLtitleLink" href="https://dl.acm.org/authorize?N654009" title="Get the Full Text from the ACM Digital Library">Distributed deep reinforcement learning on the cloud for autonomous driving</a>
</h3>
<ul class="DLauthors">
<li class="nameList First">Mitchell Spryn</li>
<li class="nameList">Aditya Sharma</li>
<li class="nameList">Dhawal Parkar</li>
<li class="nameList Last">Madhur Shrimal</li>
</ul>
<div class="DLabstract"><div style="display:inline"><p>This paper proposes an architecture for leveraging cloud computing technology to reduce training time for deep reinforcement learning models for autonomous driving by distributing the training process across a pool of virtual machines. By parallelizing the training process, careful design of the reward function and use of techniques like transfer learning, we demonstrate a decrease in training time for our example autonomous driving problem from 140 hours to less than 1 hour. We go over our network architecture, job distribution paradigm, reward function design and report results from experiments on small sized cluster (1--6 training nodes) of machines. We also discuss the limitations of our approach when trying to scale up to massive clusters.</p></div> </div>
<h3>
<a class="DLtitleLink" href="https://dl.acm.org/authorize?N654000" title="Get the Full Text from the ACM Digital Library">Towards a holistic software systems engineering approach for dependable autonomous systems</a>
</h3>
<ul class="DLauthors">
<li class="nameList First">Adina Aniculaesei</li>
<li class="nameList">J&#246;rg Grieser</li>
<li class="nameList">Andreas Rausch</li>
<li class="nameList">Karina Rehfeldt</li>
<li class="nameList Last">Tim Warnecke</li>
</ul>
<div class="DLabstract"><div style="display:inline"><p>Autonomous systems are gaining momentum in various application domains, such as autonomous vehicles, autonomous transport robotics and self-adaptation in smart homes. Product liability regulations impose high standards on manufacturers of such systems with respect to dependability (safety, security and privacy). Today's conventional engineering methods are not adequate for providing guarantees with respect to dependability requirements in a cost-efficient manner, e.g. road tests in the automotive industry sum up millions of miles before a system can be considered sufficiently safe. System engineers will no longer be able to test and respectively formally verify autonomous systems during development time in order to guarantee the dependability requirements in advance. In this vision paper, we introduce a new holistic software systems engineering approach for autonomous systems, which integrates development time methods as well as operation time techniques. With this approach, we aim to give the users a transparent view of the confidence level of the autonomous system under use with respect to the dependability requirements. We present already obtained results and point out research goals to be addressed in the future.</p></div> </div>
<h3>
<a class="DLtitleLink" href="https://dl.acm.org/authorize?N654001" title="Get the Full Text from the ACM Digital Library">Towards a methodology for training with synthetic data on the example of pedestrian detection in a frame-by-frame semantic segmentation task</a>
</h3>
<ul class="DLauthors">
<li class="nameList First">Atanas Poibrenski</li>
<li class="nameList">Janis Sprenger</li>
<li class="nameList Last">Christian M&#252;ller</li>
</ul>
<div class="DLabstract"><div style="display:inline"><p>In order to make highly/fully automated driving safe, synthetic training and validation data will be required, because critical road situations are too divers and too rare. A few studies on using synthetic data have been published, reporting a general increase in accuracy. In this paper, we propose a novel method to gain more in-depth insights in the quality, performance, and influence of synthetic data during training phase in a bounded setting. We demonstrate this method for the example of pedestrian detection in a frame-by-frame semantic segmentation class.</p></div> </div>
<h2>SESSION: Verification of self-driving cars</h2>
<div class="DLabstract"> </div>
<h3>
<a class="DLtitleLink" href="https://dl.acm.org/authorize?N654002" title="Get the Full Text from the ACM Digital Library">Deep learning for self-driving cars: chances and challenges</a>
</h3>
<ul class="DLauthors">
<li class="nameList First">Qing Rao</li>
<li class="nameList Last">Jelena Frtunikj</li>
</ul>
<div class="DLabstract"><div style="display:inline"><p>Artificial Intelligence (AI) is revolutionizing the modern society. In the automotive industry, researchers and developers are actively pushing deep learning based approaches for autonomous driving. However, before a neural network finds its way into series production cars, it has to first undergo strict assessment concerning functional safety. The chances and challenges of incorporating deep learning for self-driving cars are presented in this paper.</p></div> </div>
<h3>
<a class="DLtitleLink" href="https://dl.acm.org/authorize?N654003" title="Get the Full Text from the ACM Digital Library">Exploiting learning and scenario-based specification languages for the verification and validation of highly automated driving</a>
</h3>
<ul class="DLauthors">
<li class="nameList First">Werner Damm</li>
<li class="nameList Last">Roland Galbas</li>
</ul>
<div class="DLabstract"><div style="display:inline"><p>We propose a series of methods based on learning key structural properties from traffic data-basis and on statistical model checking, ultimately leading to the construction of a scenario catalogue capturing requirements for controlling criticality for highly autonomous vehicles. We sketch underlying mathematical foundations which allow to derive formal confidence levels that vehicles tested by such a scenario catalogue will maintain the required control of criticality in real traffic matching the probability distributions of key parameters of data recorded in the reference data base employed for this process.</p></div> </div>
<h3>
<a class="DLtitleLink" href="https://dl.acm.org/authorize?N654004" title="Get the Full Text from the ACM Digital Library">Automotive safety and machine learning: initial results from a study on how to adapt the ISO 26262 safety standard</a>
</h3>
<ul class="DLauthors">
<li class="nameList First">Jens Henriksson</li>
<li class="nameList">Markus Borg</li>
<li class="nameList Last">Cristofer Englund</li>
</ul>
<div class="DLabstract"><div style="display:inline"><p>Machine learning (ML) applications generate a continuous stream of success stories from various domains. ML enables many novel applications, also in safety-critical contexts. However, the functional safety standards such as ISO 26262 did not evolve to cover ML. We conduct an exploratory study on which parts of ISO 26262 represent the most critical gaps between safety engineering and ML development. While this paper only reports the first steps toward a larger research endeavor, we report three adaptations that are critically needed to allow ISO 26262 compliant engineering, and related suggestions on how to evolve the standard.</p></div> </div>
</div>
</div>
</body>
</html>
